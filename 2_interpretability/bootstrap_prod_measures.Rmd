---
title: "Bootstrapping (with and without replacement) for entropy and other productivity measures"
output: md_document
---

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(entropy)
library(ggpubr)
library(patchwork)
library(extrafont)
loadfonts()

options(dplyr.summarise.inform = FALSE)
theme_set(theme_bw(base_size = 10))
theme_update(text = element_text(family = "Linux Libertine Display G"))
```

```{r}
# Read in data from classic bootstrapping (wrepl) and pseudo-bootstrapping (no replacement)
freqdist_iter <- read.csv('iterdata/freqdist_iter_500.csv', encoding='UTF-8')
freqdist_iter_wrepl <- read.csv('iterdata/freqdist_iter_500_wrepl.csv', encoding='UTF-8')

# Relabel suffixes with dash in front (e.g., -heit) and reorder in order of productivity.
freqdist_iter$suffix <- factor(freqdist_iter$suffix,
                levels = c("heit", "schaft", "nis"),
                labels = c('-heit', '-schaft', '-nis'))
freqdist_iter_wrepl$suffix <- factor(freqdist_iter_wrepl$suffix,
                levels = c("heit", "schaft", "nis"),
                labels = c('-heit', '-schaft', '-nis'))
```

# Classic bootstrapping (sampling w/ replacement)

## Type count

```{r}
types_summ_wrepl <- freqdist_iter_wrepl %>% 
  group_by(suffix, sample_size, iter) %>% 
  summarise(n_types = n()) %>% 
  group_by(suffix, sample_size) %>%
  summarise(
    mean_n_types = mean(n_types),
    min = min(n_types),
    max = max(n_types))

(p_ntypes_wrepl <- types_summ_wrepl %>% 
  ggplot(aes(x=sample_size, y=mean_n_types, colour=suffix)) +
  geom_point()  +
  geom_line() +
  geom_errorbar(aes(ymin = min,
                    ymax = max),
                alpha = 0.5,
                width = 0.05) +
  labs(y = 'Count',
       x = 'Sample size (tokens)',
       title = 'Type count',
       colour = element_blank()) +
  scale_x_continuous(trans = 'log10') +
  scale_y_continuous(trans = 'log10') +
  scale_colour_grey(guide = guide_legend(label.theme = element_text(face = "italic", 
                                                                    family = "Linux Libertine Display G",
                                                                    size = 8))) + 
  NULL)

freqdist_iter_wrepl %>% 
  filter(iter==1 & sample_size == max(sample_size)) %>% 
  group_by(suffix) %>% 
  summarise(ntypes = n())
```

Print out some counts for illustration.

```{r}
freqdist_iter_wrepl %>% 
  filter(iter==1 & sample_size %in% c(1e04, 5e05)) %>% 
  group_by(suffix, sample_size) %>% 
  summarise(ntypes = n())
```


## Potential productivity

```{r}
pp_summ_wrepl <- freqdist_iter_wrepl %>% 
  filter(n_tokens == 1) %>%
  group_by(suffix, iter, sample_size) %>%
  summarise(n_hapaxes = sum(n_tokens)) %>% 
  mutate(pp = n_hapaxes/sample_size) %>% 
  group_by(suffix, sample_size) %>%
  summarise(mean_pp = mean(pp),
            min = min(pp),
            max = max(pp))

(p_pp_wrepl <- pp_summ_wrepl %>% 
    ggplot(aes(x=sample_size, y=mean_pp, colour=suffix)) +
    geom_point()  +
    geom_line() +
    geom_errorbar(aes(ymin = min,
                      ymax = max),
                  alpha = 0.5,
                  width = 0.05) +
    labs(y = 'Potential productivity',
         x = 'Sample size (tokens)',
         title = 'Potential productivity',
         colour = element_blank()) +
    ylim(c(0,1)) +
    scale_x_continuous(trans = 'log10') +
    scale_colour_grey(guide = guide_legend(label.theme = element_text(face = "italic", 
                                                                      family = "Linux Libertine Display G",
                                                                      size = 8))) + 
    NULL)
```

## S

```{r}
get_fZM_S <- function(freqdist){
  # Given a frequency distribution, computes an fZM model on it and returns the estimate of S.
  #
  # Arg:
  #   freqdist: df that contains a column n_tokens: the number of times each type appears.
  # Returns:
  #   Either an integer (the estimate of S for freqdist) or NA (if model parameters couldn't be estimated).
  
  
  # Step 1: Convert freq distribution to a frequency spectrum, format headers the way zipfR likes, 
  # write df to external .spc file (overwritten every time but that's fine), and read back in. 
  # Now ready for use with zipfR.
  # https://github.com/epankratz/diachronic-productivity-thesis/blob/master/scripts-and-data/functions.R#L5
  freqspec <- as.data.frame(table(freqdist$n_tokens))
  names(freqspec) <- c("m", "Vm")
  write.table(freqspec, "iterdata/making_spcs.spc", sep="\t", row.names=FALSE)
  freqspec <- read.spc("iterdata/making_spcs.spc")
  
  # Step 2: Fit a fZM model; get S or, if the model crashes, return NA.
  # https://github.com/epankratz/diachronic-productivity-thesis/blob/master/scripts-and-data/functions.R#L425 
  fzm_s <- tryCatch(
    {
      # The 'try' part: This is the output if there is no error.
      lnre("fzm", freqspec, exact=F)$S
    },
    error=function(error){
      # The 'except' part: Return NA if there is an error, e.g., if parameter estimation fails.
      return(NA)
    }
  )
  
  return(fzm_s)
}
```

```{r warning=FALSE, eval=FALSE}
s_vec <- freqdist_iter_wrepl %>% 
  group_by(suffix, iter, sample_size) %>% 
  group_map(~ get_fZM_S(.x)) %>% 
  unlist()

# Get a df of the grouping variables as they were used for group_map()
# and add the resulting vector as a column. Should match.
s_iter_wrepl <- freqdist_iter_wrepl %>% 
  select(suffix, iter, sample_size) %>% 
  distinct()
s_iter_wrepl$s <- s_vec

write.csv(s_iter_wrepl, 'iterdata/s_iter500_wrepl.csv', row.names=FALSE)
```

```{r}
s_iter_wrepl <- read.csv('iterdata/s_iter500_wrepl.csv')
s_iter_wrepl$suffix <- factor(s_iter_wrepl$suffix, levels = c('-heit', '-schaft', '-nis'))

# The S values can be really bizarrely huge sometimes, so I'm going to get rid of the extreme outliers
# (defined as those more than 1.5 times the IQR away from the 25th and 75% quantile).

remove_outliers <- function(x) {
  # Function from 
  # https://stackoverflow.com/questions/4787332/how-to-remove-outliers-from-a-dataset/4788102#4788102
  qnt <- quantile(x, probs=c(.25, .75), na.rm = TRUE)
  H <- 1.5 * IQR(x, na.rm = TRUE)
  y <- x
  y[x < (qnt[1] - H)] <- NA
  y[x > (qnt[2] + H)] <- NA
  y
}

# If we use dplyr's group_by() and then filter for outliers, we get rid of the entire group if it contains 
# an outlier, so I'll do it the more tedious way: pivot_wider() to get one sample size as a column and 
# iterations as rows, make a separate df for each sfx, replace outliers with NA in each col, rbind the 
# individual dfs together again, and pivot longer.
s_wide_wrepl <- s_iter_wrepl %>% 
  pivot_wider(values_from = s, names_from = sample_size)

# Rows 1:50 are -heit, 51:100 are -nis, 101:150 are -schaft.
# Cols 3:17 are the fifteen different sample sizes.
no_outl_wide_wrepl <- rbind(
  as.data.frame(lapply(s_wide_wrepl[1:50, 3:17], remove_outliers)),
  as.data.frame(lapply(s_wide_wrepl[51:100, 3:17], remove_outliers)),
  as.data.frame(lapply(s_wide_wrepl[101:150, 3:17], remove_outliers))
)

no_outl_iter_wrepl <- cbind(s_wide_wrepl[1:2], no_outl_wide_wrepl) %>% 
  pivot_longer(cols = starts_with('X'), values_to = 's', names_to = 'sample_size') %>% 
  mutate(sample_size = as.numeric(gsub('X', '', sample_size)))

# Now we can compute the mean and range for the remaining, non-outlier values.
s_summ_wrepl <- no_outl_iter_wrepl %>%
  group_by(suffix, sample_size) %>%
  summarise(
    mean_s = mean(s, na.rm=TRUE),
    min = min(s, na.rm=TRUE),
    max = max(s, na.rm=TRUE))
```

### S plot

```{r}
(p_s_wrepl <- s_summ_wrepl %>% 
   ggplot(aes(x=sample_size, y=mean_s, colour=suffix)) +
   geom_point()  +
   geom_line() +
   geom_errorbar(aes(ymin = min,
                     ymax = max),
                 alpha = 0.5,
                 width = 0.05) +
   labs(y = 'S',
        x = 'Sample size (tokens)',
        colour = element_blank(),
        title = 'S') +
   scale_x_continuous(trans = 'log10') +
   scale_y_continuous(trans = 'log10',
                      labels = function(x) format(x, scientific = TRUE)) +
   scale_colour_grey(guide = guide_legend(label.theme = element_text(face = "italic", 
                                                                     family = "Linux Libertine Display G",
                                                                     size = 8))) + 
   theme(axis.title.y = element_text(face = "italic"),
         plot.title = element_text(face = "italic")) +
   NULL)

```

## All measures plot

```{r}
# Combine plots using patchwork (nicely aligns left edge)
p_ntypes_wrepl / p_pp_wrepl / p_s_wrepl + 
  plot_layout(guides='collect') &
  theme(legend.position='bottom')

ggsave('imgs/alt-measures.pdf', device=cairo_pdf, width=10, height=21, units='cm')
```


## Entropy

```{r}
# Compute entropy for each sample.
ent_col_wrepl <- freqdist_iter_wrepl %>% 
  group_by(suffix, iter, sample_size) %>% 
  group_map(~entropy.empirical(.x$n_tokens, unit='log2')) %>% 
  unlist()

# Get a df of the grouping variables as they were used for group_map(),
# reorder -nis and -schaft so that they match the factor levels,
# and add the resulting vector as a column.
ent_iter_wrepl <- freqdist_iter_wrepl %>% 
  select(suffix, iter, sample_size) %>% 
  distinct()
ent_iter_wrepl <- rbind(
  ent_iter_wrepl[1:7500,],      # heit
  ent_iter_wrepl[15001:22500,], # schaft
  ent_iter_wrepl[7501:15000,]   # nis
)
ent_iter_wrepl$ent <- ent_col_wrepl

ent_summ_wrepl <- ent_iter_wrepl %>% 
  group_by(suffix, sample_size) %>% 
  summarise(
    mean_ent = mean(ent),
    min = min(ent),
    max = max(ent)
  )

ent_summ_wrepl %>%   
  ggplot(aes(x=sample_size, y=mean_ent, colour=suffix)) +
  geom_point()  +
  geom_line() +
  geom_errorbar(aes(ymin = min,
                    ymax = max),
                alpha = 0.5,
                width = 0.05) +
  labs(y = 'Shannon entropy (bits)',
       x = 'Sample size (tokens)',
       colour = element_blank()) +
  scale_x_continuous(trans = 'log10') +
  scale_colour_grey(guide = guide_legend(label.theme = element_text(face = "italic", 
                                                                    family = "Linux Libertine Display G",
                                                                    size = 8))) +
  NULL
ggsave('imgs/entropy.pdf', device=cairo_pdf, width=12, height=8, units = 'cm')
```


## VGC

These VGCs are cheating a little, because instead of using the order that the tokens appear in the sample, I'm randomising the order of the types in the sample.
I have to do this because I didn't save the full sample in each bootstrapping iteration, just the counts, so I can't reconstruct the order.
But in practice, most analyses don't care about order anyway, and this plot is also so peripheral and just intended as illustration, so it's fine.

```{r}
make_vgc_data <- function(sample){
  # Gets vocabulary growth data for given sample.
  # Arg:
  #   sample: a vector of tokens
  # Returns:
  #   a data frame in which N is num tokens seen and V is vocab size
  
  emp <- data.frame(matrix(ncol=2))
  names(emp) <- c('N', 'V')
  discovered <- c()
  
  for(idx in 1:length(sample)){
    curr_token <- sample[idx]
    
    # Add token to discovered if previously unseen
    if(!(is.element(curr_token, discovered))){
      discovered <- c(discovered, curr_token)
    }
    
    # Write results to emp; N = idx, V = length(discovered) when we've seen idx tokens.
    emp[idx,] <- c(idx, length(discovered))
  }
  
  return(emp)
}
```

Get the types in the 10,000-token samples in iteration 1.

```{r eval=FALSE}
size <- 1e04

heit_samp <- freqdist_iter_wrepl %>% 
  filter(iter==1 & sample_size == size & suffix == '-heit') %>% 
  mutate(type = as.character(type)) %>%
  select(type, n_tokens) %>%
  uncount(n_tokens) %>%  # grabs from given col the number of times a row should be repeated
  unlist(use.names = FALSE) %>% 
  sample()
  
nis_samp <- freqdist_iter_wrepl %>% 
  filter(iter==1 & sample_size == size & suffix == '-nis') %>% 
  mutate(type = as.character(type)) %>%
  select(type, n_tokens) %>%
  uncount(n_tokens) %>%  # grabs from given col the number of times a row should be repeated
  unlist(use.names = FALSE) %>% 
  sample()

schaft_samp <- freqdist_iter_wrepl %>% 
  filter(iter==1 & sample_size == size & suffix == '-schaft') %>% 
  mutate(type = as.character(type)) %>%
  select(type, n_tokens) %>%
  uncount(n_tokens) %>%  # grabs from given col the number of times a row should be repeated
  unlist(use.names = FALSE) %>% 
  sample()

heit_vgc <- make_vgc_data(heit_samp)
schaft_vgc <- make_vgc_data(schaft_samp)
nis_vgc <- make_vgc_data(nis_samp)

vgc_data <- bind_rows(list(`-heit`=heit_vgc, `-nis`=nis_vgc, `-schaft`=schaft_vgc), .id='suffix')

write.csv(vgc_data, 'iterdata/vgc_data.csv', row.names = FALSE)
```

### VGC plot

```{r}
vgc_data <- read.csv('iterdata/vgc_data.csv')
vgc_data$suffix <- factor(vgc_data$suffix, levels = c('-heit', '-schaft', '-nis'))

vgc_data %>% 
  ggplot(aes(x=N, y=V, colour=suffix)) +
  geom_line() +
  labs(y = 'Types seen',
       x = 'Tokens seen',
       colour = element_blank()) +
  scale_colour_grey(guide = guide_legend(label.theme = element_text(face = "italic", 
                                                                    family = "Linux Libertine Display G",
                                                                    size = 8))) +
  NULL

ggsave('imgs/vgc.pdf', device=cairo_pdf, width=12, height=6, units = 'cm')
```

# Pseudo-bootstrapping Ã  la BaroniEvert2016 (sampling without replacement)

## Type count

```{r}
types_summ <- freqdist_iter %>% 
  group_by(suffix, sample_size, iter) %>% 
  summarise(n_types = n()) %>% 
  group_by(suffix, sample_size) %>%
  summarise(
    mean_n_types = mean(n_types),
    min = min(n_types),
    max = max(n_types))

p_ntypes <- types_summ %>% 
  ggplot(aes(x=sample_size, y=mean_n_types, colour=suffix)) +
  geom_point()  +
  geom_line() +
  geom_errorbar(aes(ymin = min,
                    ymax = max),
                alpha = 0.5,
                width = 0.05) +
  labs(y = 'Count',
       x = 'Sample size (tokens)',
       title = 'Type count',
       colour = element_blank()) +
  scale_x_continuous(trans = 'log10') +
  scale_y_continuous(trans = 'log10') +
  scale_colour_grey() + 
  theme(plot.margin = unit(c(1,1,1,1), "lines")) +
  NULL
```


## Potential productivity


```{r}
pp_summ <- freqdist_iter %>% 
  filter(n_tokens == 1) %>%
  group_by(suffix, iter, sample_size) %>%
  summarise(n_hapaxes = sum(n_tokens)) %>% 
  mutate(pp = n_hapaxes/sample_size) %>% 
  group_by(suffix, sample_size) %>%
  summarise(mean_pp = mean(pp),
            min = min(pp),
            max = max(pp))

p_pp <- pp_summ %>% 
  ggplot(aes(x=sample_size, y=mean_pp, colour=suffix)) +
  geom_point()  +
  geom_line() +
  geom_errorbar(aes(ymin = min,
                    ymax = max),
                alpha = 0.5,
                width = 0.05) +
  labs(y = 'Potential productivity',
       x = 'Sample size (tokens)',
       title = 'Potential productivity',
       colour = element_blank()) +
  ylim(c(0,1)) +
  scale_x_continuous(trans = 'log10') +
  scale_colour_grey() +
  theme(plot.margin = unit(c(1,1,1,1), "lines")) +
  NULL
```

## S

```{r warning=FALSE, eval=FALSE}
s_vec <- freqdist_iter %>% 
  group_by(suffix, iter, sample_size) %>% 
  group_map(~ get_fZM_S(.x)) %>% 
  unlist()

# Get a df of the grouping variables as they were used for group_map()
# and add the resulting vector as a column. Should match.
s_iter <- freqdist_iter_wrepl %>% 
  select(suffix, iter, sample_size) %>% 
  distinct()
s_iter$s <- s_vec

write.csv(s_iter, 'iterdata/s_iter500.csv', row.names=FALSE)
```

```{r}
s_iter <- read.csv('iterdata/s_iter500.csv')
levels(s_iter$suffix) <- c('-heit', '-nis', '-schaft')
s_iter$suffix <- factor(s_iter$suffix, levels = c('-heit', '-schaft', '-nis'))

# Remove outliers as above.
s_wide <- s_iter %>% 
  pivot_wider(values_from = s, names_from = sample_size)

# Rows 1:50 are -heit, 51:100 are -nis, 101:150 are -schaft.
# Cols 3:17 are the fifteen different sample sizes.
no_outl_wide <- rbind(
  as.data.frame(lapply(s_wide[1:50, 3:17], remove_outliers)),
  as.data.frame(lapply(s_wide[51:100, 3:17], remove_outliers)),
  as.data.frame(lapply(s_wide[101:150, 3:17], remove_outliers))
)

no_outl_iter <- cbind(s_wide[1:2], no_outl_wide) %>% 
  pivot_longer(cols = starts_with('X'), values_to = 's', names_to = 'sample_size') %>% 
  mutate(sample_size = as.numeric(gsub('X', '', sample_size)))

# Now we can compute the mean and range for the remaining, non-outlier values.
s_summ <- no_outl_iter %>%
  group_by(suffix, sample_size) %>%
  summarise(
    mean_s = mean(s, na.rm=TRUE),
    min = min(s, na.rm=TRUE),
    max = max(s, na.rm=TRUE))
```

### S plot

```{r}
p_s <- s_summ %>% 
  ggplot(aes(x=sample_size, y=mean_s, colour=suffix)) +
  geom_point()  +
  geom_line() +
  geom_errorbar(aes(ymin = min,
                    ymax = max),
                alpha = 0.5,
                width = 0.05) +
  labs(y = 'S',
       x = 'Sample size (tokens)',
       colour = element_blank(),
       title = 'S') +
  scale_x_continuous(trans = 'log10') +
  scale_y_continuous(trans = 'log10') +
  scale_colour_grey() +
  theme(plot.margin = unit(c(1,1,1,1), "lines"),
        axis.title.y = element_text(face = "italic"),
        plot.title = element_text(face = "italic")) +
  NULL
```


## Entropy

```{r}
# Compute entropy for each sample.
ent_col <- freqdist_iter %>% 
  group_by(suffix, iter, sample_size) %>% 
  group_map(~entropy.empirical(.x$n_tokens, unit='log2')) %>% 
  unlist()

# Get a df of the grouping variables as they were used for group_map(),
# reorder -nis and -schaft so that they match the factor levels,
# and add the resulting vector as a column.
ent_iter <- freqdist_iter %>% 
  select(suffix, iter, sample_size) %>% 
  distinct()
ent_iter <- rbind(
  ent_iter[1:7500,],      # heit
  ent_iter[15001:22500,], # schaft
  ent_iter[7501:15000,]   # nis
)
ent_iter$ent <- ent_col

ent_summ <- ent_iter %>% 
  group_by(suffix, sample_size) %>% 
  summarise(
    mean_ent = mean(ent),
    min = min(ent),
    max = max(ent)
  )

ent_summ %>%   
  ggplot(aes(x=sample_size, y=mean_ent, colour=suffix)) +
  geom_point()  +
  geom_line() +
  geom_errorbar(aes(ymin = min,
                    ymax = max),
                alpha = 0.5,
                width = 0.05) +
  labs(y = 'Shannon entropy',
       x = 'Sample size (tokens)',
       colour = 'Suffix') +
  scale_x_continuous(trans = 'log10') +
  scale_colour_grey() +
  NULL
```

# Contrast the replacement methods

## Type count 

```{r}
types_summ_both <- bind_rows(list(`With repl.` = types_summ_wrepl, `Without repl.` = types_summ), .id = 'repl')

(p_ntypes_samp <- types_summ_both %>% 
    ggplot(aes(x=sample_size, y=mean_n_types, colour=suffix, linetype=repl, shape=repl)) +
    geom_point()  +
    geom_line() +
    geom_errorbar(aes(ymin = min,
                      ymax = max),
                  alpha = 0.5,
                  width = 0.1) +
    labs(y = 'Count',
         x = 'Sample size (tokens)',
         colour = element_blank(),
         linetype = element_blank(),
         shape = element_blank()) +
    scale_x_continuous(trans = 'log10') +
    scale_y_continuous(trans = 'log10') +
    scale_colour_grey(guide = guide_legend(order=1, 
                                           label.theme = element_text(face = "italic", 
                                                                      family = "Linux Libertine Display G",
                                                                      size = 8))) + 
    NULL)

ggsave('imgs/boot-typecount.pdf', device=cairo_pdf, width=14, height=10, units='cm')
```

## Potential productivity

```{r}
pp_summ_both <- bind_rows(list(`With repl.` = pp_summ_wrepl, `Without repl.` = pp_summ), .id = 'repl')

(p_pp_samp <- pp_summ_both %>% 
    ggplot(aes(x=sample_size, y=mean_pp, colour=suffix, linetype=repl, shape=repl)) +
    geom_point()  +
    geom_line() +
    geom_errorbar(aes(ymin = min,
                      ymax = max),
                  alpha = 0.5,
                  width = 0.1) +
    labs(y = 'Potential productivity',
         x = 'Sample size (tokens)',
         colour = element_blank(),
         linetype = element_blank(),
         shape = element_blank()) +
    scale_x_continuous(trans = 'log10') +
    scale_colour_grey(guide = guide_legend(order=1, 
                                           label.theme = element_text(face = "italic", 
                                                                      family = "Linux Libertine Display G",
                                                                      size = 8))) + 
    NULL)

ggsave('imgs/boot-pp.pdf', device=cairo_pdf, width=14, height=10, units='cm')
```

## S

```{r}
s_summ_both <- bind_rows(list(`With repl.` = s_summ_wrepl, `Without repl.` = s_summ), .id = 'repl')

(p_s_samp <- s_summ_both %>% 
    ggplot(aes(x=sample_size, y=mean_s, colour=suffix, linetype=repl, shape=repl)) +
    geom_point()  +
    geom_line() +
    geom_errorbar(aes(ymin = min,
                      ymax = max),
                  alpha = 0.5,
                  width = 0.1) +
    labs(y = 'S',
         x = 'Sample size (tokens)',
         colour = element_blank(),
         linetype = element_blank(),
         shape = element_blank()) + 
    scale_x_continuous(trans = 'log10') +
    scale_y_continuous(trans = 'log10',
                       labels = function(x) format(x, scientific = TRUE)) +
    scale_colour_grey(guide = guide_legend(order=1, 
                                           label.theme = element_text(face = "italic", 
                                                                      family = "Linux Libertine Display G",
                                                                      size = 8))) + 
   theme(axis.title.y = element_text(face = "italic")) +
    NULL)

ggsave('imgs/boot-s.pdf', device=cairo_pdf, width=14, height=10, units='cm')
```

## Entropy

```{r}
ent_summ_both <- bind_rows(list(`With repl.` = ent_summ_wrepl, `Without repl.` = ent_summ), .id = 'repl')

(p_ent_samp <- ent_summ_both %>% 
    ggplot(aes(x=sample_size, y=mean_ent, colour=suffix, linetype=repl, shape=repl)) +
    geom_point()  +
    geom_line() +
    geom_errorbar(aes(ymin = min,
                      ymax = max),
                  alpha = 0.5,
                  width = 0.1) +
    labs(y = 'Shannon entropy',
         x = 'Sample size (tokens)',
         colour = element_blank(),
         linetype = element_blank(),
         shape = element_blank()) +
    scale_x_continuous(trans = 'log10') +
    scale_colour_grey(guide = guide_legend(order=1, 
                                           label.theme = element_text(face = "italic", 
                                                                      family = "Linux Libertine Display G",
                                                                      size = 8))) + 
    NULL)

ggsave('imgs/boot-entropy.pdf', device=cairo_pdf, width=14, height=10, units='cm')
```


# R session info

```{r}
sessionInfo()
```

