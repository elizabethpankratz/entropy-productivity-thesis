{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script reads in the list of most frequent lemmas from DECOW and filters it for those that are most likely to be monomorphemic.\n",
    "The tabular output is saved in `simplex_filtered1.csv`, and the output to be fed into SMOR is saved in `simplex_filtered2.tosmor`.\n",
    "\n",
    "(The reason why SMOR can't be used exclusively is because it fails to recognise certain affixes.\n",
    "But it's pretty good at compounds.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqlist = pd.read_csv('infiles/decow16bx.lp', sep='\\t', names=['lemma', 'POS', 'freq'], keep_default_na=False)\n",
    "\n",
    "# Only keep lemmata with frequency > 10000. (Impressionistically, there aren't many simplexes below that point at all.)\n",
    "freqlist = freqlist[freqlist['freq'] > 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for POSs that can possibly be monomorphemic (i.e., excluding stuff like finite verbs and various cliticised pronouns)\n",
    "pos_to_keep = set(['NN', 'ADJA', 'ADJD', 'VVINF', 'ADV', 'PTKVZ', 'APPR', \n",
    "               'KOUS' , 'KON', 'APPO', 'PTKNEG', 'PWAV', 'PWS', 'PWAT', \n",
    "               'PRF', 'VMINF', 'PPOSS', 'APZR', 'PRELS', 'PRELAT', 'ART',\n",
    "               'PTKANT', 'KOUI', 'VAINF', 'KOKOM', 'PTKZU'])\n",
    "\n",
    "freqlist = freqlist[ freqlist['POS'].isin(pos_to_keep) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31577\n"
     ]
    }
   ],
   "source": [
    "print(len(freqlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove words from the sample that contain particular affixes. \n",
    "The question of how strict these criteria should be is definitely very subjective, but I'm going for a high-precision, low-recall approach: I really want the things in my sample to be simplexes, and it's OK if there are some true simplexes that don't make it into my final sample.\n",
    "Some of these suffixes are definitely not productive suffixes of German, but they appear a lot in loan words, so this is also a not-perfect-but-okay way to hone in on core German phonology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_adj_adv_startswith = ['un', 'ge', 'ab', 'an', 'auf', 'aus', 'ein', 'mit', 'nach', 'weg', 'zu', 'be', 'ent', 'er', 'ver', 'zer',\n",
    "                      'durch', 'um', 'über', 'unter', 'vor', 'hin', 'her', 'ur', 'ik', 'iv']\n",
    "noun_startswith = [pfx.capitalize() for pfx in verb_adj_adv_startswith]\n",
    "noun_endswith = ['ung', 'heit', 'keit', 'tum', 'nis', 'er', 'ion', 'in', 'schaft', 'ende', 'chen', 'tät', 'ist', 'ment',\n",
    "                'ant', 'ar', 'är', 'äß', 'ik', 'um', 'ur', 'age',  'ei', 'erie', 'al']\n",
    "adj_adv_endswith = ['isch', 'end', 'elnd', 'ernd', 'bar', 'lich', 'lichst', 'los', 'ional', 'voll', 'ell', 'iert', 'är', 'iv', \n",
    "                    'ig', 'os', 'ös', 'weise', 'er', 'el', 'frei', 'haft', 'al', 'wert', 'stens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pfx in verb_adj_adv_startswith:\n",
    "    freqlist = freqlist[ ~((freqlist['POS'] == 'ADJA') & (freqlist['lemma'].str.startswith(pfx))) ]\n",
    "    freqlist = freqlist[ ~((freqlist['POS'] == 'ADJD') & (freqlist['lemma'].str.startswith(pfx))) ]\n",
    "    freqlist = freqlist[ ~((freqlist['POS'] == 'ADV') & (freqlist['lemma'].str.startswith(pfx))) ]\n",
    "    freqlist = freqlist[ ~((freqlist['POS'] == 'VVINF') & (freqlist['lemma'].str.startswith(pfx))) ]\n",
    "    \n",
    "for pfx in noun_startswith:\n",
    "    freqlist = freqlist[ ~((freqlist['POS'] == 'NN') & (freqlist['lemma'].str.startswith(pfx))) ]\n",
    "\n",
    "for sfx in noun_endswith:\n",
    "    freqlist = freqlist[ ~((freqlist['POS'] == 'NN') & (freqlist['lemma'].str.endswith(sfx))) ]\n",
    "\n",
    "for sfx in adj_adv_endswith:\n",
    "    freqlist = freqlist[ ~((freqlist['POS'] == 'ADJA') & (freqlist['lemma'].str.endswith(sfx))) ]\n",
    "    freqlist = freqlist[ ~((freqlist['POS'] == 'ADJD') & (freqlist['lemma'].str.endswith(sfx))) ]\n",
    "    freqlist = freqlist[ ~((freqlist['POS'] == 'ADV') & (freqlist['lemma'].str.endswith(sfx))) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14498\n"
     ]
    }
   ],
   "source": [
    "print(len(freqlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqlist.to_csv('outfiles/simplex_filtered1.csv', index=False)\n",
    "freqlist.lemma.to_csv('outfiles/simplex_filtered1.tosmor', index=False, header=False, sep=\"\\t\", line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step happens off-stage.\n",
    "I apply SMOR to `outfiles/simplex_filtered1.tosmor` to yield `infiles/simplex_filtered1.smored`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
