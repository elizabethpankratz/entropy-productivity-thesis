{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstraps samples from the full samples of 35 German suffixes from DECOW16B (synchronic) and RIDGES (diachronic).\n",
    "Computes their entropy and frequency distributions. Saves outfiles in `iterdata/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "import os\n",
    "\n",
    "PATH_TO_COW_SAMPLES = '../1_data/35_samples/7_analysis_samples/'\n",
    "PATH_TO_RIDGES_SAMPLES = '../1_data/ridges_samples/'\n",
    "SFXS = [fn.split('_')[0] for fn in os.listdir(PATH_TO_COW_SAMPLES)]\n",
    "R_SFXS = ['er', 'heit', 'ung']\n",
    "R_PERS = ['1482-1549', '1550-1649', '1650-1749', '1750-1849', '1850-1914']\n",
    "NUM_ITER = 100\n",
    "SIZE_FACTORS = [2**-idx for idx in range(5)]\n",
    "\n",
    "W_REPL = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECOW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-age ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-ament ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-and ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-ant ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-anz ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-ateur ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-ation ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-ator ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-atur ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-eA ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-el ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-ement ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-end ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-ent ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-enz ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-er ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-eur ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-eV ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-heit ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-ie ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-iker ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-ikum ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-ik ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-iment ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-ismus ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-ist ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-itaet ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-iteur ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-ition ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-itur ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-ium ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-ling ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-nis ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-schaft ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n",
      "\n",
      "-ung ==============================\n",
      "Done iteration 20\n",
      "Done iteration 40\n",
      "Done iteration 60\n",
      "Done iteration 80\n",
      "Done iteration 100\n"
     ]
    }
   ],
   "source": [
    "FREQDIST_LIST = []\n",
    "ENTROPY_LIST = []\n",
    "\n",
    "for sfx in SFXS:\n",
    "    print('\\n'+sfx, '='*30)\n",
    "    \n",
    "    # Read in sample.\n",
    "    curr_sfx_df = pd.read_csv(PATH_TO_COW_SAMPLES + sfx + '_sample.csv')\n",
    "    \n",
    "    # Generate the factors that we'll subset the samples using: full size, then half (2^-1), quarter (2^-2), eighth (2^-3).\n",
    "    # Then get subsample sizes for the current sample.\n",
    "    sizes = [int(np.ceil(len(curr_sfx_df) * factor)) for factor in SIZE_FACTORS]\n",
    "\n",
    "    for iter_idx in range(1, NUM_ITER+1):\n",
    "    \n",
    "        for size_idx in range(len(sizes)):\n",
    "            \n",
    "            size = sizes[size_idx]\n",
    "            factor = SIZE_FACTORS[size_idx]\n",
    "        \n",
    "            # Draw a random subsample from curr_sfx_df of size 'size'.\n",
    "            rd_idcs = np.random.choice(curr_sfx_df.index, size = size, replace = W_REPL)\n",
    "            curr_subset = curr_sfx_df.iloc[rd_idcs].reset_index().rename(columns = {'index':'orig_idx'})\n",
    "\n",
    "            # Compute the frequency distribution of the types in this sample and use this to compute entropy.\n",
    "            # First, count the occurrences of values in 'lemma' and add a rank column.\n",
    "            freq_df = pd.DataFrame(curr_subset.lemma.value_counts()).reset_index().rename(columns={'index':'type', 'lemma':'n_tokens'})\n",
    "            freq_df['rank'] = list(range(1, len(freq_df)+1))\n",
    "            freq_df['iter'] = iter_idx\n",
    "            freq_df['sfx'] = sfx\n",
    "            freq_df['sample_size'] = size\n",
    "            freq_df['factor'] = factor\n",
    "            \n",
    "            # Now get the Shannon entropy of the values in n_tokens.\n",
    "            ent = entropy(freq_df['n_tokens'], base = 2)\n",
    "            \n",
    "            # Append this information to FREQDIST_LIST and ENTROPY_LIST for export.\n",
    "            FREQDIST_LIST.append(freq_df)\n",
    "            ENTROPY_LIST.append( {'iter':iter_idx, 'sfx':sfx, 'sample_size':size, 'factor':factor, 'entropy':ent, 'n_types':len(freq_df)} )\n",
    "            \n",
    "        if iter_idx % 20 == 0:\n",
    "            print('Done iteration', iter_idx)\n",
    "\n",
    "# Use pd.concat on FREQDIST_LIST, since it's a list of dfs.\n",
    "pd.concat(FREQDIST_LIST)[['sfx','iter','factor','sample_size','rank','type','n_tokens']].to_csv('iterdata/freqdist_iter_wrepl.csv', index=False)\n",
    "\n",
    "# Can just use pd.DataFrame on the other two lists, since they're lists of dicts.\n",
    "pd.DataFrame(ENTROPY_LIST)[['sfx','iter','factor','sample_size','n_types','entropy']].to_csv('iterdata/entropy_iter_wrepl.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RIDGES data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "er ==============================\n",
      "Done 1482-1549 - iteration 20\n",
      "Done 1482-1549 - iteration 40\n",
      "Done 1482-1549 - iteration 60\n",
      "Done 1482-1549 - iteration 80\n",
      "Done 1482-1549 - iteration 100\n",
      "Done 1550-1649 - iteration 20\n",
      "Done 1550-1649 - iteration 40\n",
      "Done 1550-1649 - iteration 60\n",
      "Done 1550-1649 - iteration 80\n",
      "Done 1550-1649 - iteration 100\n",
      "Done 1650-1749 - iteration 20\n",
      "Done 1650-1749 - iteration 40\n",
      "Done 1650-1749 - iteration 60\n",
      "Done 1650-1749 - iteration 80\n",
      "Done 1650-1749 - iteration 100\n",
      "Done 1750-1849 - iteration 20\n",
      "Done 1750-1849 - iteration 40\n",
      "Done 1750-1849 - iteration 60\n",
      "Done 1750-1849 - iteration 80\n",
      "Done 1750-1849 - iteration 100\n",
      "Done 1850-1914 - iteration 20\n",
      "Done 1850-1914 - iteration 40\n",
      "Done 1850-1914 - iteration 60\n",
      "Done 1850-1914 - iteration 80\n",
      "Done 1850-1914 - iteration 100\n",
      "\n",
      "heit ==============================\n",
      "Done 1482-1549 - iteration 20\n",
      "Done 1482-1549 - iteration 40\n",
      "Done 1482-1549 - iteration 60\n",
      "Done 1482-1549 - iteration 80\n",
      "Done 1482-1549 - iteration 100\n",
      "Done 1550-1649 - iteration 20\n",
      "Done 1550-1649 - iteration 40\n",
      "Done 1550-1649 - iteration 60\n",
      "Done 1550-1649 - iteration 80\n",
      "Done 1550-1649 - iteration 100\n",
      "Done 1650-1749 - iteration 20\n",
      "Done 1650-1749 - iteration 40\n",
      "Done 1650-1749 - iteration 60\n",
      "Done 1650-1749 - iteration 80\n",
      "Done 1650-1749 - iteration 100\n",
      "Done 1750-1849 - iteration 20\n",
      "Done 1750-1849 - iteration 40\n",
      "Done 1750-1849 - iteration 60\n",
      "Done 1750-1849 - iteration 80\n",
      "Done 1750-1849 - iteration 100\n",
      "Done 1850-1914 - iteration 20\n",
      "Done 1850-1914 - iteration 40\n",
      "Done 1850-1914 - iteration 60\n",
      "Done 1850-1914 - iteration 80\n",
      "Done 1850-1914 - iteration 100\n",
      "\n",
      "ung ==============================\n",
      "Done 1482-1549 - iteration 20\n",
      "Done 1482-1549 - iteration 40\n",
      "Done 1482-1549 - iteration 60\n",
      "Done 1482-1549 - iteration 80\n",
      "Done 1482-1549 - iteration 100\n",
      "Done 1550-1649 - iteration 20\n",
      "Done 1550-1649 - iteration 40\n",
      "Done 1550-1649 - iteration 60\n",
      "Done 1550-1649 - iteration 80\n",
      "Done 1550-1649 - iteration 100\n",
      "Done 1650-1749 - iteration 20\n",
      "Done 1650-1749 - iteration 40\n",
      "Done 1650-1749 - iteration 60\n",
      "Done 1650-1749 - iteration 80\n",
      "Done 1650-1749 - iteration 100\n",
      "Done 1750-1849 - iteration 20\n",
      "Done 1750-1849 - iteration 40\n",
      "Done 1750-1849 - iteration 60\n",
      "Done 1750-1849 - iteration 80\n",
      "Done 1750-1849 - iteration 100\n",
      "Done 1850-1914 - iteration 20\n",
      "Done 1850-1914 - iteration 40\n",
      "Done 1850-1914 - iteration 60\n",
      "Done 1850-1914 - iteration 80\n",
      "Done 1850-1914 - iteration 100\n"
     ]
    }
   ],
   "source": [
    "R_FREQDIST_LIST = []\n",
    "R_ENTROPY_LIST = []\n",
    "\n",
    "for sfx in R_SFXS:\n",
    "    print('\\n'+sfx, '='*30)\n",
    "    \n",
    "    # Read in sample.\n",
    "    curr_sfx_df = pd.read_csv(PATH_TO_RIDGES_SAMPLES + sfx + '.csv')\n",
    "    \n",
    "    # First we have to transform the RIDGES data into the format we expect: \n",
    "    # rather than a type frequency distribution, a sample in which each type \n",
    "    # is actually contained the given number of times.\n",
    "    perlist = curr_sfx_df.period.repeat(curr_sfx_df.frequency)\n",
    "    lemlist = curr_sfx_df.lemma.repeat(curr_sfx_df.frequency)\n",
    "    curr_sfx_df = pd.DataFrame({'period': perlist, 'lemma': lemlist})\n",
    "    \n",
    "    for per in R_PERS:\n",
    "        \n",
    "        curr_per_df = curr_sfx_df[curr_sfx_df.period == per].reset_index(drop=True)\n",
    "    \n",
    "        # Generate the factors that we'll subset the samples using: full size, then half (2^-1), quarter (2^-2), eighth (2^-3).\n",
    "        # Then get subsample sizes for the current sample.\n",
    "        sizes = [int(np.ceil(len(curr_per_df) * factor)) for factor in SIZE_FACTORS]\n",
    "\n",
    "        for iter_idx in range(1, NUM_ITER+1):\n",
    "\n",
    "            for size_idx in range(len(sizes)):\n",
    "\n",
    "                size = sizes[size_idx]\n",
    "                factor = SIZE_FACTORS[size_idx]\n",
    "\n",
    "                # Draw a random subsample from curr_per_df of size 'size'.\n",
    "                rd_idcs = np.random.choice(curr_per_df.index, size = size, replace = W_REPL)\n",
    "                curr_subset = curr_per_df.iloc[rd_idcs].reset_index().rename(columns = {'index':'orig_idx'})\n",
    "\n",
    "                # Compute the frequency distribution of the types in this sample and use this to compute entropy.\n",
    "                # First, count the occurrences of values in 'lemma' and add a rank column.\n",
    "                freq_df = pd.DataFrame(curr_subset.lemma.value_counts()).reset_index().rename(columns={'index':'type', 'lemma':'n_tokens'})\n",
    "                freq_df['rank'] = list(range(1, len(freq_df)+1))\n",
    "                freq_df['iter'] = iter_idx\n",
    "                freq_df['sfx'] = sfx\n",
    "                freq_df['sample_size'] = size\n",
    "                freq_df['period'] = per\n",
    "                freq_df['factor'] = factor\n",
    "\n",
    "                # Now get the Shannon entropy of the values in n_tokens.\n",
    "                ent = entropy(freq_df['n_tokens'], base = 2)\n",
    "\n",
    "                # Append this information to FREQDIST_LIST and ENTROPY_LIST for export.\n",
    "                R_FREQDIST_LIST.append(freq_df)\n",
    "                R_ENTROPY_LIST.append( {'iter':iter_idx, 'sfx':sfx, 'sample_size':size, 'factor':factor, 'entropy':ent, 'period':per, 'n_types':len(freq_df)} )\n",
    "\n",
    "            if iter_idx % 20 == 0:\n",
    "                print('Done', per, '- iteration', iter_idx)\n",
    "\n",
    "# Use pd.concat on FREQDIST_LIST, since it's a list of dfs.\n",
    "pd.concat(R_FREQDIST_LIST)[['sfx','iter','period','factor','sample_size','rank','type','n_tokens']].to_csv('iterdata/ridges_freqdist_iter_wrepl.csv', index=False)\n",
    "\n",
    "# Can just use pd.DataFrame on the other two lists, since they're lists of dicts.\n",
    "pd.DataFrame(R_ENTROPY_LIST)[['sfx','iter','period','factor','sample_size','n_types','entropy']].to_csv('iterdata/ridges_entropy_iter_wrepl.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filse in `iterdata/` whose names do not end in `_wrepl` were also generated with this script, but with `W_REPL = False`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
